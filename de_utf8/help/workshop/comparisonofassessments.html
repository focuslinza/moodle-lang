<h2>Vergleich von Bewertungen</h2>
<p>Im Workshop wird üblicherweise die Arbeit gleichermaßen
von dem/der Trainer/in und den TN bewertet. Wenn
Musterlösungen verwandt werden, werden diese zuerst von
dem/der Trainer/in bewertet und danach einzelne
Musterlösungen den TN vorgelegt. Die Arbeiten der TN werden
sorgfältig von dem/der Trainer/in kommentiert und bewertet
und möglicherweise auch von einer kleinen Zahl anderer TN.
Der/die Trainer/in kann die Gewichtung der Bewertung einer Arbeit
durch andere TN festlegen. Der Rest der Benotung besteht aus der
Bewertung durch den/die Trainer/in. Die Gewichtung kann am Ende
des Workshops festgelegt werden. Die Bewertungen, die die TN
durchführen können ebenfalls bewertet werden. Dabei
richtet sich die Bewertung nach der Übereinstimmung mit der
Bewertung des/der Trainers/in. Wenn er/sie keine Note vergibt
wird die durchschnittliche Bewertung der Teilnehmer/innen zu
Grunde gelegt.</p>
<p>Der Grad der Übereinstimmung zwischen der Bewertung durch
die TN und dem/der Trainer/in basiert auf den Unterschieden
zwischen den vergebenen Punkten bei den einzelnen
Bewertungskriterien. Diese müssen noch in eine
nachvollziehbare Benotung übertragen werden. Dazu erlaubt
die Option "Vergleich der Bewertungen" dem Trainer eine genaue
Kontrolle wie die Vergleiche in Benotungen umgesetzt werden.</p>
<p>Damit Sie eine ungefähre Vorstellung der Wirkung dieser
Option erhalten, sei es mit einem (wirklich einfachen) Beispiel
demonstriert. In unserem Beispiel erfolgt die Bewertung anhand
von 10 Ja/Nein Fragen. (z.B.: Ist das Chart richtig formatiert?
Oder: Ist der errechnete Gewinn 100,66 $?) Wenn die Einstellung
"Sehr lax"" gewählt wurde, ergibt die vollständige
Übereinstimmung zwischen den Bewertungen der TN und des/der
Trainers/in einen Ergebniswert von 100 %, ist nur eine Frage
abweichend bewertet lautet das Ergebnis 90 %, für jede
weitere abweichend bewertete Frage sinkt der Wert um jeweils 10
%. Diese Bewertung erscheint sehr logisch, aber warum wird sie
als sehr lax bezeichnet? Stellen Sie sich vor, ein TN vergibt die
Bewertung nach dem Zufallsprinzip. Dann wird er wahrscheinlich
50% richtige Bewertungen vornehmen und erhält eine Bewertung
von 50 % als Basis für die Note. Wenn die Einstellung auf
lax geändert wird, wird der Zufallsfaktor mit 20 % gesetzt.
Mit der Fair Option auf 0 in den meisten Fällen. In diesem
Level wird eine 50 % Bewertung vergeben, wenn zwei Bewertungen
von zehn nicht übereinstimmen. Bei drei nicht
übereinstimmenden Bewertungen wird eine 25 % Bewertung
vergeben. Die Einstellung strickt führt bei zwei
Nicht-Übereinstimmung zu einer Bewertung von 40%, sehr
strickt zu einer Bewertung von 35% bei einer
Nichtübereinstimmung.</p>
<p>Dieses Beispiel ist sicher ein wenig künstlich, da
zumeist Bewertungsskalen mit einer stärkeren Abstufung
verwandt werden als nur Ja/Nein. Die Berechnung des Ergebnisses
des Vergleichs erfolgt jedoch in gleicher Weise. Die
verschiedenen Level (sehr lax, lax, fair,...) dienen nun dazu,
die Bewertung fein abzustimmen. Wenn Sie den Eindruck haben, die
Bewertung ist zu niedrig, ändern Sie einfach den Level in
Richtung sehr lax. Wenn Sie den Eindruck haben, die Bewertung ist
insgesamt zu postiv, ändern Sie den Level in Richtung sehr
strickt. Es ist eine Frage des Ausprobierens. Ein guter
Startpunkt ist die mittlere Einstellung fair.</p>
<p>Während des Ablaufs des Workshops bekommen Sie einen
eindruck davon, ob die Bewertungen zu hoch oder zu niedrig sind.
Die Benotungen sind in der Administrationsseite des Workshops
ersichtlich. Sie können dann die Einstellungen anpassen und
die Benotungen neu errechnen lassen. Die Neuberechnung erfolgt
durch Klick auf den Link Neubenotung der Arbeiten der TN auf der
Administrationsseite. Dies kann jederzeit im Verlauf des
Workshops vorgenommen werden.</p>